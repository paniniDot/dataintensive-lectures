{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poiché il testo umano non segue delle regole precise (refusi, tempi coniugati male, convenzioni non scritte, sarcasmo, ecc.), ovvero non è testo strutturato, non è facile capire come poterlo far comprendere a una macchina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Come prima cosa va fatto del pre-processing che consiste nell’operare delle trasformazioni ai dati in input per poterli fornire a dei modelli.\n",
    "\n",
    "1. **Tokenization**. È la pratica di segmentare il testo in token più piccoli. Può trattarsi di word tokenization se si splitta in parole o sentences tokenization se un testo lungo viene suddiviso prima in frasi.\n",
    "2. **POS**. In secondo luogo occorre fare quello che prende il nome di Part Of Sentence tagging. Le parole hanno un proprio ruolo grammaticale (nome, verbo, aggettivo) all’interno di una frase, addirittura la stessa parola in contesti diversi può avere POS differenti. Il POS tagging è la procedura che assegna un POS ad ogni parola. Questo può essere fatto o meno.\n",
    "3. **Filtrare la sequenza di parole**. Occorre filtrare la sequenza da caratteri spuri (tag HTML o altro).\n",
    "4. **Casefolding**. Poiché le parole possono essere scritte tutte in maiuscolo, tutte in minuscolo o con la prima lettera in maiuscolo pur avendo lo stesso significato, quello che si fa tipicamente è convertire tutto nello stesso formato, in questo modo si è in grado di uniformare e sintetizzare parole uguali ma in formati originariamente diversi.\n",
    "5. **Rimozione di stopword**. Le stopword sono quelle parole che non hanno contenuto informativo (come articoli, pronomi, ecc) ma che sono inserite nel testo poiché facenti parti del linguaggio naturale. Vengono tipicamente inserite in liste utilizzate per ripulire il testo.\n",
    "6. **Lemmatizzazione** Le parole vengono tipicamente modificate a seconda del contesto per adattarle alla frase (declinazioni, coniugazioni, ecc.). Ad esempio, il verbo “trovare” può essere trovato come “trovano”, “trovasti”, “trovò”, ecc. sebbene indichino tutti la stessa cosa. La lemmatizzazione si occupa proprio di normalizzare queste parole e riportarle alla loro forma base. Non è facile farlo, specie perché dipende dalla lingua in uso.\n",
    "7. **Stemming**. Algoritmo decisamente più semplice della lemmatizzazione, nato però con lo stesso scopo. La differenza è che questo ricava da ogni parola la sua radice morfologica e unisce parole con stessa radice. Questo può essere anche più impreciso perché potrebbe unire anche verbi e aggettivi nello stesso token ad esempio. Sebbene meno preciso è più semplice da implementare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Text Search (FTS)\n",
    "Il primo tipo di algoritmi in merito al NLP sono detti **information retrieval**. Questi sistemi si occupano,\n",
    "-\tdata una **query**, cioè una stringa di parole chiave rappresentati l’informazione richiesta, \n",
    "-\tdi fornire un **oggetto** che condensa queste informazioni, quindi tipicamente fornire un elenco di documenti (che chiaramente presentano testo non strutturato) che trattano di quell’informazione, ovviamente dal documento più rilevante a quello meno. \n",
    "Se la query contiene più termini, inoltre, va specificato se devono comparire tutti o solo alcuni, se vanno trovati nello stesso ordine con cui sono elencati nella query, se possono anche essere restituiti testi con parole simili, ecc. \n",
    "Questi sistemi si misurano su due parametri che riassumono un po’ i concetti di qualità e quantità spesso in contrasto\n",
    "1.\t**Precision**. Consiste nella precisione con cui funziona l’algoritmo. È il rapporto fra documenti pertinenti trovati e i documenti forniti (qualità).\n",
    "2.\t**Recall**. Consiste nel rapporto fra quantità di documenti reputati pertinenti al punto da essere forniti in output, e l’insieme di tutti i documenti pertinenti nella collezione.\n",
    "\n",
    "Esistono diversi **modelli** per questa disciplina che si classificano in base alle teorie matematiche alla base o alla modalità con cui si ha interdipendenza dei termini.\n",
    "-\t**Modello Booleano Standard**. Modello più semplice in assoluto. I documenti vengono suddivisi in rilevanti e non rilevanti e vengono restituiti senza un ordine specifico. I termini della query possono essere concatenati con operatori logici\n",
    "    -\tA AND B restituisce l’insieme dei documenti che sono rilevanti sia per il termine A che per il termine B\n",
    "    - A OR B restituisce l’insieme dei documenti che sono rilevanti o per A o per B\n",
    "    \n",
    "    È semplice da usare e implementare ma non restituisce documenti con un ordine preciso e risulta troppo semplice, non coglie tutte le sfaccettature del linguaggio.\n",
    "\n",
    "- **Modello Vettoriale**. Questo modello si basa sulla teoria dei vettori. I documenti vengono rappresentati come vettori di termini e la query viene rappresentata come un vettore di termini. La similarità fra i vettori viene calcolata con la coseno similarità. I documenti vengono restituiti in ordine di similarità. Questo modello è più complesso da implementare ma è più preciso e flessibile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione di semantica testuale\n",
    "Fino ad ora abbiamo visto tecniche che interpretano la sintassi e la struttura del testo per ricavarne gli elementi di base (ad esempio gli argomenti trattati). Oltre a questo, una sfida più complessa è capire il significato esatto del testo. Tuttavia, questo è un risultato molto complicato da ottenere per un calcolatore visto quanto detto prima.\n",
    "Per poter comprendere il significato di un testo dobbiamo \n",
    "-\tConoscere tutte le parole al suo interno (capire i significati possibili per la parola X e conoscere parole simili)\n",
    "-\tCapire come queste siano in relazione fra loro \n",
    "\n",
    "Gli algoritmi di estrazione semantica usano una **base testuale esterna** del linguaggio per poter interpretare correttamente un testo. **WordNet** è il database lessicale in inglese più grande in circolazione\n",
    "-\t include più di 150k termini divisi in 4 POS (nomi, verbi, aggettivi, avverbi)\n",
    "-\togni parola è organizzata in **synset** (synonimous set) ovvero un set di sinonimi per quella parola. Ogni synset ha una breve descrizione del significato di quei sinonimi. Una stessa parola può far parte di più synset\n",
    "-\tTra synset e termini definiti in essi sono esposte anche le **relazioni semantiche e lessicali**\n",
    "\n",
    "Una **relazione semantica** rappresenta che relazione vi è fra due synset o due termini. Ad esempio possiamo avere \n",
    "-\t**Iponimia**. Essere un tipo specifico di. Cane is-a animale.\n",
    "-\t**Meronimia**. Essere parte/membro/sostanza di.\n",
    "-\t**Implicazione**. Un’azione ne comporta un’altra. \n",
    "-\t**Antonimia**. Essere opposto di.\n",
    "\n",
    "Di seguito si riporta un esempio di struttura di word net\n",
    "<img src=\"imgs/wordnet.png\" alt=\"wordnet\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation (WSD)\n",
    "La Word Sense Disambiguation (WSD) è la procedura che associa ad ogni parola il suo significato a seconda del contesto. Cioè, disambigua le parole (ad esempio a “spina” è attribuito, a seconda del contesto, ad un aculeo di animale o a una presa di corrente). Per comprendere il contesto di una parola, tipicamente si cerca di comprendere le parole vicino a cui è inserita. Ad esempio, l’algoritmo di Lesk disambigua una parola controllando quante delle parole vicine nella frase si ripresentano nella sua definizione. Tornando al concetto di spina, ad esempio, avremo\n",
    "-\t**Definizione**. Una spina elettrica è un connettore che può essere inserito in una presa di corrente complementare.\n",
    "-\t**Frase**. La spina elettrica è inserita nella presa di corrente (in elettronica), Elemento indurito, acuminato, e pungente (botanica)\n",
    "\n",
    "È evidente che si sta parlando di spina elettrica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Le **named entities** sono specifiche entità a cui ci si può riferire per nome in un testo (ad esempio una persona come “Il presidente Obama” o un luogo “Germania” o ancora un’organizzazione “ONU”). Sono considerate tali anche date e numeri.\n",
    "La **named entity recognition (NER)** consiste nell’individuare e classificare per tipo le named entities, ad esempio in “persone”, “luoghi”, “organizzazioni”. In Python esistono librerie come NLTK (NL ToolKit) e SpaCy che hanno implementato algoritmi di NER.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Come rappresentare il testo\n",
    "\n",
    "Nell’analisi di un testo serve spesso rappresentare il contenuto generale in forma sintetica o comunque schematizzata (strutturata). Poiché le parole, una volta assegnato il rispettivo POS, non richiedono di essere disposte nell’ordine originale per comprendere il contenuto del testo, possono essere strutturate in svariati modi.\n",
    "\n",
    "-\t**Bag of Word (BoW)**. Questa rappresentazione inserisce in una tabella (parola-occorrenze) tutte le parole distinte del testo con le rispettive occorrenze. A questo servono processi come lo stemming o lemmatizzazione in fase di pre-processing: sintetizzando e raggruppando parole è possibile ridurre la dimensione di questa tabella.\n",
    "\n",
    "<img src=\"imgs/bow.png\" alt=\"bow\" width=150>\n",
    "\n",
    " \n",
    "-\t**N-gram**. Sono una tecnica per arricchire ulteriormente il BOW. Consistono nella concatenazione di n parole ritenute concettualmente collegate fra loro. L’indice “n” rappresenta il numero di parole che sono raggruppati. Sono inclusi anche molti n-gram non significativi (ad esempio in figura le parole rosse).\n",
    "\n",
    "<img src=\"imgs/ngram.png\" alt=\"ngram\" width=150> \n",
    " \n",
    "-\t**Rappresentazione vettoriale**. Questo bow appena trovato può essere inserito in un vettore. In particolare, si consideri un dizionario D di termini distinti. L’i-esimo elemento del vettore corrisponde alle occorrenze dell’i-esimo termine del dizionario D. ovviamente il vettore sarà composto da |D| elementi.\n",
    "\n",
    "<img src=\"imgs/vect.png\" alt=\"vect\" width=400>\n",
    "\n",
    "-\t**Vector Space Model (VSM)**. Racchiude in sé tutte le occorrenze in N documenti distinti delle $|D|$ parole del dizionario comune. \n",
    "L’insieme dei documenti può essere rappresentata come una matrice termini-documenti $D \\times N$ dove l’elemento $(i,j)$ rappresenta l’occorrenza della parola $i-$ esima nel documento $j-$ esimo.\n",
    "\n",
    "<img src=\"imgs/vsm.png\" alt=\"wordnet\" width=400>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term weighting\n",
    "Ogni parola ha un’importanza (o peso) all’interno di un documento. Cioè, vi saranno quelle parole più significative di altre per comprendere il significato del contenuto del testo. Le parole di “stopword” sono considerate pressoché a peso 0 all’interno del documento e pertanto sono rimosse in fase di pre-processing. Una prima metrica di importanza di una parola è il numero di occorrenze che essa ha avuto nel testo.\n",
    "Esistono però metriche più accurate basate su **schemi di term weighting**. In particolare, considerando un vector space model (VSM) si possono usare le seguenti modalità \n",
    "-\t**Tf** (term frequency). È un fattore “locale” che pesa la rilevanza di ciascun termine sul singolo documento, è il numero di apparizioni del termine all’interno del documento.\n",
    "-\t**Idf** (inverse document frequency). È un fattore “globale” che pesa l’importanza di ciascun termine nell’intera collezione. È più alto per termini che compaiono in meno documenti, in quanto più utili a distinguere questi documenti dagli altri. \n",
    "-\t**Tf-idf**. Dato un termine t e un documento d è il prodotto dei logaritmi di tf e idf\n",
    "$$\n",
    "tf.idf(t,d) = \\underbrace{\\log (f(t,d))}_{tf} \\cdot \\underbrace{\\log \\left( \\frac{|D|}{|d \\in D : t \\in d|} \\right)}_{itf}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizzazione dei vettori\n",
    "I documenti non hanno tutti la stessa lunghezza, pertanto, a lunghezza maggiore corrispondono anche pesi più elevati (ovviamente più lungo è il documento e maggiori saranno le occorrenze di tutte le parole, questo però non garantisce che l’argomento riconosciuto come importante sia più rilevante in quel testo che in un altro più breve). **Per garantire pari peso a documenti di lunghezza diversa si normalizzano i vettori** ottenuti in seguito al term weighting.\n",
    "\n",
    "$$\n",
    "w(t,d)_{\\text{norm}} = \\frac{w(t,d)}{\\sqrt{\\sum_{\\tau \\in D} w(\\tau, d)^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarità coseno\n",
    "Rappresentando i documenti sottoforma di vettori nel medesimo spazio, è possibile misurarne la similarità con varie metriche. Una delle varie metriche è quella della **similarità coseno** pari al coseno dell’angolo fra vettori. \n",
    "\n",
    "$$\n",
    "\\cos(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{|\\mathbf{a}| \\cdot |\\mathbf{b}|} = \\frac{\\sum_{i=1}^n a_i \\cdot b_i}{\\sqrt{\\sum_{i=1}^n a_i^2} \\cdot \\sqrt{\\sum_{i=1}^n b_i^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model vs Modello Booleano\n",
    "A differenza del modello booleano, con VSM l’output di una query è una lista con ranking effettivo dei documenti (sono ordinati dal più rilevante al meno). Inoltre, la misura dell’output non è limitata come nel booleano dove poteva essere solamente (sì o “no”, “presente” o “non presente”), nel caso del VSM, infatti, ogni parola ha un peso calcolato con le metriche td-dif. Attraverso questo peso è possibile avere degli iperparametri come **soglia di similarità**, si prendono documenti aventi pesi simili per termini logicamente simili. Non è però possibile usare espressioni booleane in VSM, tuttavia esistono modelli che combinano VSM e logica booleana. Lo si fa in questo modo:\n",
    "-\tIl modello prima ottiene i documenti che soddisfano l’espressione booleana\n",
    "-\tIl risultato viene poi sottoposto al modello VSM che ordina i documenti calcolandone il rank tramite pesi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ricerca di un termine e indicizzazione\n",
    "La ricerca di documenti rilevanti sulla base di una query è di fatto la ricerca di quei documenti in cui sono presenti delle occorrenze di termini dati nella query. Tipicamente quello che si può fare è una ricerca sequenziale su tutti i documenti, verificandone la rilevanza di ciascuno alla query.\n",
    "Questo però comporta un notevole dispendio di tempo per documenti lunghi poiché vanno confrontate tutte le parole e dunque la complessità diventa $O(N)$ (con $N$ = # documenti su cui cercare).\n",
    "<img src=\"imgs/textmap.png\" alt=\"Struttura dati documento-termini\" width=600>\n",
    "Una cosa più intelligente da fare potrebbe essere quella di applicare indicizzazione. Una tipica struttura usata è l’inverted index che prevede di avere una mappa in cui la chiave è il termine mentre il valore è la lista di documenti in cui compare.  L’accesso è praticamente immediato ($O(1)$)\n",
    "<img src=\"imgs/termmap.png\" alt=\"Struttura dati termine-documenti\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer satisfaction da dati testuali\n",
    "La customer satisfaction è la pratica che consente di valutare l’apprezzamento per un prodotto da parte degli utenti in base alle loro recensioni. Qualora le recensioni siano numeriche (valutazioni da 1 a 5 stelle) la valutazione è semplice, se però vi è del testo le cose si complicano.\n",
    "-\tLa prima cosa che viene in mente di fare è estrapolare le parole chiave di una recensione che indicano soddisfazione o meno, ad esempio “consigliato” o “capolavoro” per recensioni positive o “orribile”, “mediocre” per negative. Una possibilità è dunque quella di memorizzare in una lista queste parole e controllarne le occorrenze nelle recensioni. \n",
    "In particolare, l’idea è di avere una **lista di termini** usati per esprimere pareri postivi, e una per quelli negativi. Estraendo le singole parole dal testo e facendo il rapporto fra positive e negative possiamo arrivare al grado di soddisfazione dell’utente.\n",
    "-\tUn altro approccio consiste nell’**analizzare automaticamente recensioni etichettate** per estrarne un modello di conoscenza. Poiché ricercare parole chiave richiede tempo, la compilazione di liste è difficile e mai completa (inoltre varia da lingua a lingua) e per di più in base al contesto una stessa parola chiave può avere significati completamente diversi (“piccola” per una fotocamera è positiva, per una stanza d’albergo no).\n",
    "L’idea, pertanto, è quella di estrarre in automatico conoscenza sulle parole usate nel contesto specifico usando recensioni pre-etichettate come positive o negative.\n",
    "In questo viene in aiuto il **machine learning** e la **classificazione**. Il machine learning fornisce un enorme aiuto per effettuare predizioni sui dati. Occorre classificare i dati in gruppi secondo dei criteri specifici. La cosa non è facile e normalmente si usano algoritmi di apprendimento supervisionato\n",
    "    - Si fornisce all’algoritmo un dataset già pre-etichettato in classi per fargli estrarre un modello di conoscenza \n",
    "    - Il modello è usato come classificatore per predire le classi di appartenenza a dati simili\n",
    "    \n",
    "    Esistono tantissimi algoritmi di apprendimento supervisionato che generano modelli di conoscenza fra cui\n",
    "    - **Modelli probabilistici**. Calcola la classe di appartenenza più probabile a seconda delle caratteristiche dell’oggetto.\n",
    "    - **K-nearest neighbor**. Verifica quale sia la classe più ricorrente tra i k oggetti di training con caratteristiche simili a quelle dell’oggetto preso in considerazione.\n",
    "    - **Alberi decisionali, support vector machines, reti neurali**, …\n",
    "\n",
    "    Per definire le caratteristiche (features) degli oggetti si può usare una rappresentazione strutturata. Una soluzione può essere quella di rappresentare ciascun oggetto come un vettore in uno spazio multidimensionale. Ogni dimensione corrisponde a una feature degli oggetti. In questo modo è facile calcolare la similarità, ad esempio usando il metodo **similarità coseno**.\n",
    "\n",
    "In conclusione \n",
    "-\tCon il ML è possibile estrarre un classificatore da dataset etichettati con recensioni “positive” o “negative”.\n",
    "-\tIl modello così ottenuto potrà essere usato per classificare nuove recensioni in quello stesso ambito (a seconda del contesto ricordiamo che stessi termini cambiano significato.\n",
    "-\tPer trattare i testi è necessario rappresentarli come vettori. È possibile usare il Vector Space Model in cui appunto ogni termine distinto rappresenta una feature (e dunque una dimensione su cui è definito il vettore). Per confrontare due testi si può usare la similarità coseno.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con _Natural Language Processing_ (NLP) ci si riferisce all'insieme di tecniche per il processamento di **testo in linguaggio naturale** (inglese, italiano, ...)\n",
    "- Obiettivo del NLP è estrarre **informazioni di alto livello** dal testo o convertirlo in una **forma strutturata** (es. vettori e matrici) trattabile da altri algoritmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "\n",
    "- _NLTK_ (_Natural Language Toolkit_) è una delle principali librerie Python per il trattamento di testi in linguaggio naturale\n",
    "- Fornisce diversi algoritmi, spesso usati come componenti per pre-processare documenti di testo nell'ambito di analisi di dati\n",
    "- NLTK è già inclusa in Colab e Anaconda, in altri casi può essere installata con pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "                                              0.0/1.5 MB ? eta -:--:--\n",
      "     ---------                                0.4/1.5 MB 7.6 MB/s eta 0:00:01\n",
      "     ------------------------                 0.9/1.5 MB 9.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\pnmat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\pnmat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.6.3-cp311-cp311-win_amd64.whl (268 kB)\n",
      "                                              0.0/268.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 268.0/268.0 kB 8.3 MB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "                                              0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\pnmat\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.6.3 tqdm-4.65.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentazione\n",
    "\n",
    "- La _segmentazione_ (_tokenization_) consiste nella scomposizione di un testo in una **sequenza di elementi** (_token_)\n",
    "- Comunemente la segmentazione è usata per estrarre le **singole parole** da un testo, includendo opzionalmente numeri, segni di punteggiatura, ...\n",
    "- NLTK offre la funzione `word_tokenize` per scomporre una stringa in una lista di parole e segni di punteggiatura\n",
    "- La funzione utilizza un modello della lingua inglese per scomporre correttamente alcune parole\n",
    "- Usiamo la funzione `download` per scaricare tale modello (se non già scaricato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pnmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"This isn't an example, or is it?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- possiamo utilizzare il metodo `split` di Python per suddividere la frase in parole separate dagli spazi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This    isn't    an    example,    or    is    it?\n"
     ]
    }
   ],
   "source": [
    "words = sentence.split()\n",
    "# ottengo una lista di stringhe\n",
    "# uso join per stamparla isolando le singole parole\n",
    "print(\"    \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando però word_tokenize, grazie alla conoscenza della lingua, sono correttamente separati segni di punteggiatura e anche parole composte come \"isn't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This    is    n't    an    example    ,    or    is    it    ?\n"
     ]
    }
   ],
   "source": [
    "words = nltk.tokenize.word_tokenize(sentence)\n",
    "print(\"    \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words e Vector Space Model\n",
    "\n",
    "- Nel modello _Bag of Words_ (BoW), un testo è rappresentato dall'**insieme delle parole in esso**\n",
    "  - non si considera il loro ordine nella frase\n",
    "- Definito un dizionario $D$ di parole distinte, possiamo rappresentare un testo (_documento_) con un vettore che associ ad ogni parola in $D$ il numero di occorrenze in esso\n",
    "- Il _Vector Space Model_ prevede di rappresentare un insieme di documenti in uno **spazio vettoriale** comune, dove **le dimensioni corrispondono ai termini** di un dizionario comune\n",
    "- Un insieme di documenti in uno spazio vettoriale è rappresentabile con una **_matrice documenti-termini_**, di cui ogni riga costituisce il vettore ricavato dal documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definire uno spazio vettoriale\n",
    "\n",
    "- Dato un insieme di documenti di testo (in questo caso semplici frasi)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"the sky is blue\",\n",
    "    \"sky is blue and sky is beautiful\",\n",
    "    \"the beautiful sky is so blue\",\n",
    "    \"i love blue cheese\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo usare il filtro `CountVectorizer` fornito da scikit-learn per rappresentarli in uno spazio vettoriale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Con `fit_transform` costruiamo lo spazio vettoriale sulla base dei termini presenti nei documenti e otteniamo la matrice documenti-termini che li rappresenta\n",
    "  - scikit-learn include un algoritmo basilare per segmentare le parole, usato di default da `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'oggetto `dtm` ottenuto è una _matrice sparsa_, una struttura dati che rappresenta una matrice memorizzando in modo esplicito solamente i valori diversi da 0\n",
    "  - in applicazioni reali tipiche, una matrice documenti-termini contiene meno del 10% di valori diversi da 0, si ottiene così un grande risparmio di memoria\n",
    "- **Attenzione:** la matrice sparsa è simile ad un `ndarray` ma con alcune differenze, ad es. l'operatore `*`  esegue il prodotto canonico tra matrici piuttosto che quello elemento per elemento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Possiamo visualizzare la matrice in un frame, esplicitando documenti e termini a cui si riferiscono righe e colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the sky is blue</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky is blue and sky is beautiful</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the beautiful sky is so blue</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i love blue cheese</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  and  beautiful  blue  cheese  is  love  sky  \\\n",
       "the sky is blue                     0          0     1       0   1     0    1   \n",
       "sky is blue and sky is beautiful    1          1     1       0   2     0    2   \n",
       "the beautiful sky is so blue        0          1     1       0   1     0    1   \n",
       "i love blue cheese                  0          0     1       1   0     1    0   \n",
       "\n",
       "                                  so  the  \n",
       "the sky is blue                    0    1  \n",
       "sky is blue and sky is beautiful   0    0  \n",
       "the beautiful sky is so blue       1    1  \n",
       "i love blue cheese                 0    0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    dtm.toarray(),\n",
    "    index=docs,\n",
    "    columns=vect.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Col metodo `transform`, possiamo rappresentare ulteriori documenti nel medesimo spazio vettoriale tuttavia, poiché abbiamo addestrato il filtro su un set di documenti, non possiamo usare termini che non compaiono in essi, altrimenti non verranno considerati. Ad esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loving this blue sky today</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            and  beautiful  blue  cheese  is  love  sky  so  \\\n",
       "loving this blue sky today    0          0     1       0   0     0    1   0   \n",
       "\n",
       "                            the  \n",
       "loving this blue sky today    0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = \"loving this blue sky today\"\n",
    "pd.DataFrame(\n",
    "    vect.transform([new_doc]).toarray(),\n",
    "    index=[new_doc],\n",
    "    columns=vect.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non presenta una cella per \"loving\". Questo non è un grandissimo problema quando abbiamo dataset di enormi dimensioni (tanti documenti, molto lunghi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso di studio: Classificazione di recensioni\n",
    "\n",
    "- Sul Web sono continuamente pubblicate opinioni degli utenti, ad es. di film\n",
    "  - alcune di queste (es. su Amazon) sono etichettate con un numero di stelle, che indicano se sia positiva o negativa\n",
    "  - su altre (es. messaggi sui forum) non abbiamo tale informazione strutturata, ma solo il testo\n",
    "- Vogliamo addestrare un classificatore su recensioni etichettate come positive o negative, in modo che sia in grado di stimare l'orientamento di opinioni non etichettate\n",
    "- Utilizziamo un file di 10000 recensioni di film tratte da Amazon, a ciascuna delle quali è associato un punteggio da 1 a 5 stelle\n",
    "- Utilizzando il vector space model, possiamo addestrare un modello sui conteggi di tutte le parole presenti nei documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"datasets/reviews.csv.gz\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(\"https://git.io/fj4cS\", \"datasets/reviews.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le recensioni sono separate da un carattere tab e dunque bisogna indicarlo a pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"datasets/reviews.csv.gz\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come si può vedere dalla shape, il dataset contiene due colonne\n",
    "- `text` contiene il testo della recensione\n",
    "- `stars` contiene il numero di stelle (da 1 a 5) assegnato alla recensione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Romero did the right thing when he pick...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  George Romero did the right thing when he pick...      5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi esplorativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ottenere il numero di recensioni per ciascun numero di stelle\n",
    "- Disegnare un grafico a torta con la distribuzione del numero di stelle\n",
    "- Disegnare un istogramma con la distribuzione del numero di caratteri nelle recensioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "1     534\n",
       "2     704\n",
       "3    1434\n",
       "4    2620\n",
       "5    4708\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recensioni per numero di stelle\n",
    "rate_count = reviews.groupby(\"stars\").size()\n",
    "rate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Disegna grafico a torta \n",
    "rate_count.plot.pie(autopct=\"%.1f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews[\"text\"].str.len().hist(bins=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo a colpo d'occhio che ci sono molte recensioni brevi e poche lunghe. Si aggirano tutte sull'intervallo 0-1000 caratteri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suddivisione in recensioni positive e negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aggiungere al frame colonna `label` che associ ad ogni recensione la stringa `pos` se il numero di stelle è maggiore di 3, altrimenti `neg`.\n",
    "- Visualizzare il numero di valori `pos` e `neg` nella colonna `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>pos</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Romero did the right thing when he pick...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK, that makes it sound like something out of ...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- At a tribal village, a pensive Elizabeth Cur...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow! This has to be one of the more unusual mo...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevin Costner is one of those actors that I ne...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>You seen one heist film, you seen them all. Bu...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Often compared with \"The Big Chill\", and getti...</td>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>This collection of Laurel and Hardy films cont...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>I love Vin Diesel but I wish I'd skipped this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>When The Office was first shown to a UK audien...</td>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  stars  pos label\n",
       "0     George Romero did the right thing when he pick...      5  pos   pos\n",
       "1     OK, that makes it sound like something out of ...      5  pos   pos\n",
       "2     - At a tribal village, a pensive Elizabeth Cur...      5  pos   pos\n",
       "3     Wow! This has to be one of the more unusual mo...      5  pos   pos\n",
       "4     Kevin Costner is one of those actors that I ne...      5  pos   pos\n",
       "...                                                 ...    ...  ...   ...\n",
       "9995  You seen one heist film, you seen them all. Bu...      5  pos   pos\n",
       "9996  Often compared with \"The Big Chill\", and getti...      1  neg   neg\n",
       "9997  This collection of Laurel and Hardy films cont...      3  neg   neg\n",
       "9998  I love Vin Diesel but I wish I'd skipped this ...      3  neg   neg\n",
       "9999  When The Office was first shown to a UK audien...      5  pos   pos\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## aggiunta della colonna \"pos\"\n",
    "reviews[\"label\"] = np.where(reviews[\"stars\"] > 3, \"pos\", \"neg\")\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "pos    7328\n",
       "neg    2672\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificazione dei testi\n",
    "Adesso che abbiamo caricato correttamente il dataset, andremo a costruire un modello che predica se una recensione è positiva o negativa. Per farlo, useremo un Vector Space Model in cui\n",
    "- ogni riga rappresenta un testo da classificare\n",
    "- ogni colonna rappresenta una variabile che caratterizza il testo (le parole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima cosa suddividiamo il set in validation e training con scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "reviews_train, reviews_val = train_test_split(reviews, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istanziamo ora lo spazio vettoriale con `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso lo costruiamo sulla base dei documenti di training. Questo è il momento in cui vengono estratti i termini dal testo e viene costruita la matrice documenti-termini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7000x51772 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 993179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_train = vect.fit_transform(reviews_train[\"text\"])\n",
    "dtm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che di $7000 \\cdot 51772$ elementi solo $993179$ sono salvati (poiché $\\neq 0$) e dunque solo il $0.27\\%$ dei valori è salvato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo ora lo spazio vettoriale di validazione, poiché vogliamo che usi lo stesso dizionario di termini di quello di training dobbiamo usare il metodo `transform` e non `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3000x51772 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 405523 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_val = vect.transform(reviews_val[\"text\"])\n",
    "dtm_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fatto questo avremo due matrici documenti-termini, una per il training e una per la validazione. In esse ogni riga costituisce un esempio (una recensione) e ogni colonna una feature (un termine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo ora un modello di classificazione che consenta di classificare le recensioni in positive e negative. Usiamo un modello di regressione logistica, che è un modello lineare che restituisce in output un valore tra 0 e 1, che può essere interpretato come la probabilità che l'esempio appartenga alla classe positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, solver='saga')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrm = LogisticRegression(solver=\"saga\", C=10)\n",
    "lrm.fit(dtm_train, reviews_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.score(dtm_val, reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proviamo a testare il modello su nuove recensioni per vedere se funziona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [\n",
    "    \"What an awesome movie!\",\n",
    "    \"It was so bad, I hated it\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo\n",
    "- Estrarre la loro rappresentazione nello spazio vettroriale costruito sui documenti di training\n",
    "- Ottenere le etichette previste dal modello per ciascuna\n",
    "- Ottenere le distribuzioni di probabilità previste dal modello per ciascuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000soldiers</th>\n",
       "      <th>002</th>\n",
       "      <th>007</th>\n",
       "      <th>00am</th>\n",
       "      <th>00p</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zulus</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zuniga</th>\n",
       "      <th>zwart</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zylberstein</th>\n",
       "      <th>zylberstien</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What an awesome movie!</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It was so bad, I hated it</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           00  000  000soldiers  002  007  00am  00p  00pm  \\\n",
       "What an awesome movie!      0    0            0    0    0     0    0     0   \n",
       "It was so bad, I hated it   0    0            0    0    0     0    0     0   \n",
       "\n",
       "                           01  02  ...  zulu  zulus  zuni  zuniga  zwart  \\\n",
       "What an awesome movie!      0   0  ...     0      0     0       0      0   \n",
       "It was so bad, I hated it   0   0  ...     0      0     0       0      0   \n",
       "\n",
       "                           zwick  zylberstein  zylberstien  zz  \\\n",
       "What an awesome movie!         0            0            0   0   \n",
       "It was so bad, I hated it      0            0            0   0   \n",
       "\n",
       "                           zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \n",
       "What an awesome movie!                                    0  \n",
       "It was so bad, I hated it                                 0  \n",
       "\n",
       "[2 rows x 51772 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reviews_dtm = vect.transform(new_reviews)\n",
    "pd.DataFrame(\n",
    "    new_reviews_dtm.toarray(),\n",
    "    index=new_reviews,\n",
    "    columns=vect.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What an awesome movie!</th>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It was so bad, I hated it</th>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          label\n",
       "What an awesome movie!      pos\n",
       "It was so bad, I hated it   neg"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reviews_pred = lrm.predict(new_reviews_dtm)\n",
    "pd.DataFrame(\n",
    "    new_reviews_pred,\n",
    "    index=new_reviews,\n",
    "    columns=[\"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>What an awesome movie!</th>\n",
       "      <td>0.452504</td>\n",
       "      <td>0.547496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>It was so bad, I hated it</th>\n",
       "      <td>0.568155</td>\n",
       "      <td>0.431845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                neg       pos\n",
       "What an awesome movie!     0.452504  0.547496\n",
       "It was so bad, I hated it  0.568155  0.431845"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reviews_prob = lrm.predict_proba(new_reviews_dtm)\n",
    "pd.DataFrame(\n",
    "    new_reviews_prob,\n",
    "    index=new_reviews,\n",
    "    columns=lrm.classes_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questi dati ci mostrano che, sebbene il modello ci abbia preso, non era molto sicuro. Questo dovuto probabilmente al fatto che si è basato su poche parole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi dei pesi\n",
    "Di seguito vogliamo andare a valutare il peso dato ad ogni feature (parola) dal modello. Ovviamente le parole con peso negativo sono quelle che faranno abbassare la recensione mentre quelle positive la faranno salire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00                                  0.001171\n",
       "000                                 0.005085\n",
       "000soldiers                         0.000955\n",
       "002                                -0.000263\n",
       "007                                -0.012231\n",
       "                                      ...   \n",
       "zwick                               0.000944\n",
       "zylberstein                        -0.001752\n",
       "zylberstien                        -0.001752\n",
       "zz                                 -0.001464\n",
       "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz   -0.001501\n",
       "Length: 51772, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.Series(\n",
    "    lrm.coef_[0],\n",
    "    index=vect.get_feature_names_out()\n",
    ")\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con nsmallest possiamo visualizzare le parole con peso più basso, ovvero quelle che fanno abbassare la recensione maggiormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad       -0.280250\n",
       "nothing   -0.204110\n",
       "worst     -0.182329\n",
       "plot      -0.181015\n",
       "just      -0.155519\n",
       "if        -0.151890\n",
       "boring    -0.137827\n",
       "decent    -0.134235\n",
       "but       -0.134117\n",
       "minutes   -0.133387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.nsmallest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sembrano andare bene tranne alcune che vengono definite \"stopwords\" ovvero parole che non hanno un significato proprio ma che sono usate per costruire frasi. Ad esempio \"just\", \"if\", \"but\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great        0.421000\n",
       "best         0.213000\n",
       "dvd          0.205961\n",
       "excellent    0.204515\n",
       "highly       0.180481\n",
       "love         0.180272\n",
       "well         0.180220\n",
       "you          0.176888\n",
       "very         0.167119\n",
       "season       0.155834\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "Fino a questo momento l'inserimento di testo nello spazio vettoriale è stato fatto manualmente chiamando il metodo `count_vectorizer.transform` su ogni testo. Questo è un processo che può essere automatizzato con una _pipeline_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "model = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great        0.420817\n",
       "best         0.213200\n",
       "dvd          0.205622\n",
       "excellent    0.204271\n",
       "highly       0.180826\n",
       "love         0.180306\n",
       "well         0.179725\n",
       "you          0.176921\n",
       "very         0.167464\n",
       "season       0.155542\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.named_steps[\"lrm\"].coef_[0], index=model.named_steps[\"vect\"].get_feature_names_out()).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.idf\n",
    "Fino a questo momento abbiamo assegnato il peso alle variabili solamente in base alla loro frequenza all'interno del documento.\n",
    "Altra metrica di pesatura è il tf.idf che è il prodotto di due fattori.\n",
    "1. Tf. Importanza locale di una parola in un documento. È il numero di occorrenze della parola nel documento.\n",
    "2. Idf. Importanza globale di una parola in una collezione di documenti. È il logaritmo del rapporto fra il numero di documenti nella collezione e il numero di documenti in cui compare la parola. In altre parole è tanto più grande in quanti meno documenti compare: se un termine compare in tutti i documenti è probabile che sia poco specifico e quindi poco utile per distinguere i documenti. Potrebbe essere ad esempio una parola di uso comune (ad esempio \"is\" o \"the\").\n",
    "\n",
    "Tramite questa metrica, pertanto, si bilancia il peso di una parola in base alla sua frequenza nel documento e nella collezione. \n",
    "\n",
    "Con scikit-learn possiamo usare il metodo `TfidfVectorizer` per costruire uno spazio vettoriale che usi il tf.idf come metrica di pesatura. Se prima usavamo `CountVectorizer` che dal nome ci fa capire che semplicemente contava le occorrenze delle parole, ora usiamo `TfidfVectorizer` che usa il tf.idf.\n",
    "Essendo un filtro può essere inserito in una pipeline come sempre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>cheese</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sky</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the sky is blue</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488291</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.603137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sky is blue and sky is beautiful</th>\n",
       "      <td>0.440516</td>\n",
       "      <td>0.347308</td>\n",
       "      <td>0.229880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562351</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the beautiful sky is so blue</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432026</td>\n",
       "      <td>0.285953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349762</td>\n",
       "      <td>0.54797</td>\n",
       "      <td>0.432026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i love blue cheese</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346182</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       and  beautiful      blue    cheese  \\\n",
       "the sky is blue                   0.000000   0.000000  0.399210  0.000000   \n",
       "sky is blue and sky is beautiful  0.440516   0.347308  0.229880  0.000000   \n",
       "the beautiful sky is so blue      0.000000   0.432026  0.285953  0.000000   \n",
       "i love blue cheese                0.000000   0.000000  0.346182  0.663385   \n",
       "\n",
       "                                        is      love       sky       so  \\\n",
       "the sky is blue                   0.488291  0.000000  0.488291  0.00000   \n",
       "sky is blue and sky is beautiful  0.562351  0.000000  0.562351  0.00000   \n",
       "the beautiful sky is so blue      0.349762  0.000000  0.349762  0.54797   \n",
       "i love blue cheese                0.000000  0.663385  0.000000  0.00000   \n",
       "\n",
       "                                       the  \n",
       "the sky is blue                   0.603137  \n",
       "sky is blue and sky is beautiful  0.000000  \n",
       "the beautiful sky is so blue      0.432026  \n",
       "i love blue cheese                0.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "dtm = vect.fit_transform(docs)\n",
    "pd.DataFrame(\n",
    "    dtm.toarray(),\n",
    "    index=docs,\n",
    "    columns=vect.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capiamo che i valori sono tf.idf poiché ad esempio \"i love blue cheese\" ha tutte e 4 le parole distinte, se con CountVectorizer avremmo avuto 1 in ogni cella, ora abbiamo valori diversi. In particolare \"blue\" ha peso più basso poiché compare in tutti i documenti, mentre \"cheese\" ha peso più alto poiché compare solo in esso. Cioè \"cheese\" viene ritenuta più importante poiché considerata esclusiva per quel documento. Questo è molto utile quando si devono classificare gli argomenti trattati in un testo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8256666666666667"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer()),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo migliorato l'accuratezza di circa il 2% rispetto a prima. Questo è dovuto al fatto che il tf.idf è una metrica più accurata per pesare le parole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scomposizione in termini\n",
    "Abbiamo visto fin dall'inizio che il preprocessing, in particolare la fase di tokenizing, non è cosi semplice come potrebbe sembrare.\n",
    "Sappiamo che la semplice suddivisione con spazi non coglie tutti i dettagli che vorremmo, abbiamo visto che con `word_tokenizer` di nltk si riesce a migliorare essendo addestrato su un dizionario molto vasto della lingua inglese. A questo punto potremmo chiederci che tokenizer usano `TfidfVectorizer` e `CountVectorizer` di scikit-learn.\n",
    "In verità nessuno dei due, poiché usano un algoritmo ibrido implementato da scikit-learn.\n",
    "E' tuttavia possibile specificare il tokenizer da usare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito utilizziamo il metodo `str.split()` di Python per suddividere le frasi in parole. Questo metodo è molto più semplice di `word_tokenizer` e non è addestrato su un dizionario, tuttavia è molto più veloce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8093333333333333"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_split_model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(tokenizer=str.split)),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "str_split_model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "str_split_model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito utilizzeremo invece `nltk.word_tokenizer()` di nltk, che è più lento ma più accurato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.822"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tokenizer_model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(tokenizer=nltk.tokenize.word_tokenize)),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "nltk_tokenizer_model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "nltk_tokenizer_model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cosa interessante è che possiamo utilizzare un come tokenizer anche metodi personalizzati che abbiano stessa interfaccia e cioè\n",
    "- Input: stringa\n",
    "- Output: lista di stringhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8096666666666666"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_tokenizer_model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(tokenizer=lambda x: x.split(\" \"))),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "empty_tokenizer_model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "empty_tokenizer_model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riduzione della dimensionalità\n",
    "Si capisce bene che se il tokenizer crea una feature per ogni parola distinta presente nei documenti di training, la dimensionalità dello spazio vettoriale può diventare molto elevata. Questo può portare a \n",
    "- problemi di overfitting \n",
    "- tempi di addestramento molto lunghi. \n",
    "\n",
    "Può essere utile provare a **ridurre il numero di parole usate** per rappresentare i documenti.\n",
    "In particolare può capitare che esistano parole che compaino solo 1 o 2 volte in tutto l'insieme di documenti fornito. \n",
    "\n",
    "- Se da un lato abbiamo visto che l'idf valorizza quelle parole che compaiono in meno documenti perché caratterizzanti dei documenti in cui compare \n",
    "- se una feature è presente solo in 2 documenti su un milione potrebbe anche non essere rilevante (anche perché potrebbe essere un typos di una parola) e dunque potremmo eliminarla.\n",
    "\n",
    "Per risolvere esiste un iperparametro del vectorizer chiamato `min_df` che indica il numero minimo di documenti in cui deve comparire una parola per essere considerata. \n",
    "Accetta in input \n",
    "- numeri **interi**, in tal caso indica il numero minimo di documenti in cui deve comparire una parola per essere considerata\n",
    "- numero **decimale** in $[0,1]$ che rappresenta la percentuale di documenti in cui deve comparire una parola per essere considerata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8226666666666667"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(tokenizer=nltk.tokenize.word_tokenize, min_df=3)),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che l'accuratezza è praticamente la stessa pur avendo parametri in meno. Se prima ne avevamo 50k+ feature (parole), in questo caso solo 20k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21884"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vect\"].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rimozione di stopwords\n",
    "Esattamente come le parole che compaiono in pochi documenti, anche le stopwords sono parole che non sono rilevanti per la classificazione. Esse sono parole che non hanno un significato proprio ma che sono usate per costruire frasi. Ad esempio \"just\", \"if\", \"but\".\n",
    "Esistono tantissime liste di stopwords per ogni lingua, ad esempio in nltk possiamo importare quella inglese con `nltk.corpus.stopwords.words('english')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pnmat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = nltk.corpus.stopwords.words(\"english\")\n",
    "stoplist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stoplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per integrarle nel modello sarà sufficiente passarle come parametro al vectorizer (tfidf o count indifferentemente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\pnmat\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer(tokenizer=nltk.tokenize.word_tokenize, stop_words=stoplist, min_df=3)),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "model.fit(reviews_train[\"text\"], reviews_train[\"label\"])\n",
    "model.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo risultato è ottenuto avendo ridotto ulteriormente il numero di feature (parole)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21743"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.named_steps[\"vect\"].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search per riduzione dimensionalità\n",
    "In realtà l'accuratezza è leggermente calata perché potrebbe capitare che quelle parole considerate stopwords, potevano essere utili per il modello. Ecco perché è sempre opportuno testare i modelli con e senza iperparametri per capire quale sia il migliore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;lrm&#x27;,\n",
       "                                        LogisticRegression(C=10,\n",
       "                                                           solver=&#x27;saga&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;vect__min_df&#x27;: [3, 5, 10],\n",
       "                         &#x27;vect__stop_words&#x27;: [None,\n",
       "                                              [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                               &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;,\n",
       "                                               &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                               &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                               &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                               &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;,\n",
       "                                               &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;, &#x27;her&#x27;,\n",
       "                                               &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                               &#x27;its&#x27;, &#x27;itself&#x27;, ...]],\n",
       "                         &#x27;vect__tokenizer&#x27;: [None,\n",
       "                                             &lt;function word_tokenize at 0x0000016D7FEC0E00&gt;,\n",
       "                                             &lt;method &#x27;split&#x27; of &#x27;str&#x27; objects&gt;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;lrm&#x27;,\n",
       "                                        LogisticRegression(C=10,\n",
       "                                                           solver=&#x27;saga&#x27;))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;vect__min_df&#x27;: [3, 5, 10],\n",
       "                         &#x27;vect__stop_words&#x27;: [None,\n",
       "                                              [&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                               &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;,\n",
       "                                               &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                               &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;, &#x27;your&#x27;,\n",
       "                                               &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                               &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;,\n",
       "                                               &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;, &#x27;her&#x27;,\n",
       "                                               &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                               &#x27;its&#x27;, &#x27;itself&#x27;, ...]],\n",
       "                         &#x27;vect__tokenizer&#x27;: [None,\n",
       "                                             &lt;function word_tokenize at 0x0000016D7FEC0E00&gt;,\n",
       "                                             &lt;method &#x27;split&#x27; of &#x27;str&#x27; objects&gt;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;lrm&#x27;, LogisticRegression(C=10, solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('lrm',\n",
       "                                        LogisticRegression(C=10,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'vect__min_df': [3, 5, 10],\n",
       "                         'vect__stop_words': [None,\n",
       "                                              ['i', 'me', 'my', 'myself', 'we',\n",
       "                                               'our', 'ours', 'ourselves',\n",
       "                                               'you', \"you're\", \"you've\",\n",
       "                                               \"you'll\", \"you'd\", 'your',\n",
       "                                               'yours', 'yourself',\n",
       "                                               'yourselves', 'he', 'him', 'his',\n",
       "                                               'himself', 'she', \"she's\", 'her',\n",
       "                                               'hers', 'herself', 'it', \"it's\",\n",
       "                                               'its', 'itself', ...]],\n",
       "                         'vect__tokenizer': [None,\n",
       "                                             <function word_tokenize at 0x0000016D7FEC0E00>,\n",
       "                                             <method 'split' of 'str' objects>]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"vect\", TfidfVectorizer()),\n",
    "    (\"lrm\", LogisticRegression(solver=\"saga\", C=10))\n",
    "])\n",
    "\n",
    "grid = {\n",
    "    \"vect__tokenizer\": [None, nltk.tokenize.word_tokenize, str.split],\n",
    "    \"vect__min_df\": [3, 5, 10],\n",
    "    \"vect__stop_words\": [None, stoplist],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, grid, cv=skf, scoring=\"accuracy\", n_jobs=-1)\n",
    "gs.fit(reviews_train[\"text\"], reviews_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226666666666667"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(reviews_val[\"text\"], reviews_val[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vect__min_df</th>\n",
       "      <th>param_vect__stop_words</th>\n",
       "      <th>param_vect__tokenizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.485166</td>\n",
       "      <td>0.089299</td>\n",
       "      <td>0.738499</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__min_df': 3, 'vect__stop_words': None, ...</td>\n",
       "      <td>0.806341</td>\n",
       "      <td>0.812688</td>\n",
       "      <td>0.817402</td>\n",
       "      <td>0.812144</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.081501</td>\n",
       "      <td>0.356411</td>\n",
       "      <td>0.686832</td>\n",
       "      <td>0.151728</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__min_df': 10, 'vect__stop_words': None,...</td>\n",
       "      <td>0.812339</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.815688</td>\n",
       "      <td>0.812143</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.021833</td>\n",
       "      <td>0.100549</td>\n",
       "      <td>0.638834</td>\n",
       "      <td>0.035122</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__min_df': 5, 'vect__stop_words': None, ...</td>\n",
       "      <td>0.806769</td>\n",
       "      <td>0.811830</td>\n",
       "      <td>0.814831</td>\n",
       "      <td>0.811143</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.131001</td>\n",
       "      <td>0.046784</td>\n",
       "      <td>4.100166</td>\n",
       "      <td>0.125308</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function word_tokenize at 0x0000016D7FEC0E00&gt;</td>\n",
       "      <td>{'vect__min_df': 10, 'vect__stop_words': None,...</td>\n",
       "      <td>0.803770</td>\n",
       "      <td>0.805829</td>\n",
       "      <td>0.811402</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.849500</td>\n",
       "      <td>0.086301</td>\n",
       "      <td>4.787166</td>\n",
       "      <td>0.064188</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function word_tokenize at 0x0000016D7FEC0E00&gt;</td>\n",
       "      <td>{'vect__min_df': 3, 'vect__stop_words': None, ...</td>\n",
       "      <td>0.806769</td>\n",
       "      <td>0.807115</td>\n",
       "      <td>0.807115</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.854501</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.456999</td>\n",
       "      <td>0.105799</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;method 'split' of 'str' objects&gt;</td>\n",
       "      <td>{'vect__min_df': 3, 'vect__stop_words': None, ...</td>\n",
       "      <td>0.808912</td>\n",
       "      <td>0.807973</td>\n",
       "      <td>0.803686</td>\n",
       "      <td>0.806857</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.101001</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>4.316501</td>\n",
       "      <td>0.131903</td>\n",
       "      <td>10</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>&lt;function word_tokenize at 0x0000016D7FEC0E00&gt;</td>\n",
       "      <td>{'vect__min_df': 10, 'vect__stop_words': ['i',...</td>\n",
       "      <td>0.810626</td>\n",
       "      <td>0.800257</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.806428</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.881000</td>\n",
       "      <td>0.096198</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.019858</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__min_df': 3, 'vect__stop_words': ['i', ...</td>\n",
       "      <td>0.804199</td>\n",
       "      <td>0.807544</td>\n",
       "      <td>0.807115</td>\n",
       "      <td>0.806286</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.175834</td>\n",
       "      <td>0.198946</td>\n",
       "      <td>4.718500</td>\n",
       "      <td>0.070202</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;function word_tokenize at 0x0000016D7FEC0E00&gt;</td>\n",
       "      <td>{'vect__min_df': 5, 'vect__stop_words': None, ...</td>\n",
       "      <td>0.805056</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.805401</td>\n",
       "      <td>0.806286</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.488834</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>0.104996</td>\n",
       "      <td>10</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__min_df': 10, 'vect__stop_words': ['i',...</td>\n",
       "      <td>0.802485</td>\n",
       "      <td>0.804972</td>\n",
       "      <td>0.809687</td>\n",
       "      <td>0.805715</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.723165</td>\n",
       "      <td>0.108659</td>\n",
       "      <td>0.544166</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>5</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__min_df': 5, 'vect__stop_words': ['i', ...</td>\n",
       "      <td>0.802057</td>\n",
       "      <td>0.807973</td>\n",
       "      <td>0.804544</td>\n",
       "      <td>0.804858</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.644000</td>\n",
       "      <td>0.071016</td>\n",
       "      <td>0.390166</td>\n",
       "      <td>0.027861</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;method 'split' of 'str' objects&gt;</td>\n",
       "      <td>{'vect__min_df': 5, 'vect__stop_words': None, ...</td>\n",
       "      <td>0.807198</td>\n",
       "      <td>0.803258</td>\n",
       "      <td>0.801972</td>\n",
       "      <td>0.804142</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.098167</td>\n",
       "      <td>0.196284</td>\n",
       "      <td>4.638500</td>\n",
       "      <td>0.144455</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>&lt;function word_tokenize at 0x0000016D7FEC0E00&gt;</td>\n",
       "      <td>{'vect__min_df': 3, 'vect__stop_words': ['i', ...</td>\n",
       "      <td>0.804627</td>\n",
       "      <td>0.798543</td>\n",
       "      <td>0.807973</td>\n",
       "      <td>0.803714</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.969666</td>\n",
       "      <td>0.287287</td>\n",
       "      <td>4.744333</td>\n",
       "      <td>0.231025</td>\n",
       "      <td>5</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>&lt;function word_tokenize at 0x0000016D7FEC0E00&gt;</td>\n",
       "      <td>{'vect__min_df': 5, 'vect__stop_words': ['i', ...</td>\n",
       "      <td>0.801628</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.804972</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.390333</td>\n",
       "      <td>0.049534</td>\n",
       "      <td>0.360667</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>5</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>&lt;method 'split' of 'str' objects&gt;</td>\n",
       "      <td>{'vect__min_df': 5, 'vect__stop_words': ['i', ...</td>\n",
       "      <td>0.805056</td>\n",
       "      <td>0.801972</td>\n",
       "      <td>0.801972</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.435833</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>&lt;method 'split' of 'str' objects&gt;</td>\n",
       "      <td>{'vect__min_df': 3, 'vect__stop_words': ['i', ...</td>\n",
       "      <td>0.803770</td>\n",
       "      <td>0.799400</td>\n",
       "      <td>0.801543</td>\n",
       "      <td>0.801571</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.343334</td>\n",
       "      <td>0.038046</td>\n",
       "      <td>0.331333</td>\n",
       "      <td>0.017249</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;method 'split' of 'str' objects&gt;</td>\n",
       "      <td>{'vect__min_df': 10, 'vect__stop_words': None,...</td>\n",
       "      <td>0.805913</td>\n",
       "      <td>0.800257</td>\n",
       "      <td>0.798114</td>\n",
       "      <td>0.801428</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.181501</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.341666</td>\n",
       "      <td>0.033028</td>\n",
       "      <td>10</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>&lt;method 'split' of 'str' objects&gt;</td>\n",
       "      <td>{'vect__min_df': 10, 'vect__stop_words': ['i',...</td>\n",
       "      <td>0.800343</td>\n",
       "      <td>0.798114</td>\n",
       "      <td>0.792542</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.485166      0.089299         0.738499        0.022057   \n",
       "12       2.081501      0.356411         0.686832        0.151728   \n",
       "6        2.021833      0.100549         0.638834        0.035122   \n",
       "13       9.131001      0.046784         4.100166        0.125308   \n",
       "1       10.849500      0.086301         4.787166        0.064188   \n",
       "2        1.854501      0.097735         0.456999        0.105799   \n",
       "16       9.101001      0.130608         4.316501        0.131903   \n",
       "3        1.881000      0.096198         0.561667        0.019858   \n",
       "7       10.175834      0.198946         4.718500        0.070202   \n",
       "15       1.488834      0.025590         0.570833        0.104996   \n",
       "9        1.723165      0.108659         0.544166        0.006638   \n",
       "8        1.644000      0.071016         0.390166        0.027861   \n",
       "4       10.098167      0.196284         4.638500        0.144455   \n",
       "10      10.969666      0.287287         4.744333        0.231025   \n",
       "11       1.390333      0.049534         0.360667        0.035756   \n",
       "5        1.435833      0.035885         0.401500        0.007947   \n",
       "14       1.343334      0.038046         0.331333        0.017249   \n",
       "17       1.181501      0.092347         0.341666        0.033028   \n",
       "\n",
       "   param_vect__min_df                             param_vect__stop_words  \\\n",
       "0                   3                                               None   \n",
       "12                 10                                               None   \n",
       "6                   5                                               None   \n",
       "13                 10                                               None   \n",
       "1                   3                                               None   \n",
       "2                   3                                               None   \n",
       "16                 10  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "3                   3  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "7                   5                                               None   \n",
       "15                 10  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "9                   5  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "8                   5                                               None   \n",
       "4                   3  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "10                  5  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "11                  5  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "5                   3  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "14                 10                                               None   \n",
       "17                 10  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "\n",
       "                             param_vect__tokenizer  \\\n",
       "0                                             None   \n",
       "12                                            None   \n",
       "6                                             None   \n",
       "13  <function word_tokenize at 0x0000016D7FEC0E00>   \n",
       "1   <function word_tokenize at 0x0000016D7FEC0E00>   \n",
       "2                <method 'split' of 'str' objects>   \n",
       "16  <function word_tokenize at 0x0000016D7FEC0E00>   \n",
       "3                                             None   \n",
       "7   <function word_tokenize at 0x0000016D7FEC0E00>   \n",
       "15                                            None   \n",
       "9                                             None   \n",
       "8                <method 'split' of 'str' objects>   \n",
       "4   <function word_tokenize at 0x0000016D7FEC0E00>   \n",
       "10  <function word_tokenize at 0x0000016D7FEC0E00>   \n",
       "11               <method 'split' of 'str' objects>   \n",
       "5                <method 'split' of 'str' objects>   \n",
       "14               <method 'split' of 'str' objects>   \n",
       "17               <method 'split' of 'str' objects>   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'vect__min_df': 3, 'vect__stop_words': None, ...           0.806341   \n",
       "12  {'vect__min_df': 10, 'vect__stop_words': None,...           0.812339   \n",
       "6   {'vect__min_df': 5, 'vect__stop_words': None, ...           0.806769   \n",
       "13  {'vect__min_df': 10, 'vect__stop_words': None,...           0.803770   \n",
       "1   {'vect__min_df': 3, 'vect__stop_words': None, ...           0.806769   \n",
       "2   {'vect__min_df': 3, 'vect__stop_words': None, ...           0.808912   \n",
       "16  {'vect__min_df': 10, 'vect__stop_words': ['i',...           0.810626   \n",
       "3   {'vect__min_df': 3, 'vect__stop_words': ['i', ...           0.804199   \n",
       "7   {'vect__min_df': 5, 'vect__stop_words': None, ...           0.805056   \n",
       "15  {'vect__min_df': 10, 'vect__stop_words': ['i',...           0.802485   \n",
       "9   {'vect__min_df': 5, 'vect__stop_words': ['i', ...           0.802057   \n",
       "8   {'vect__min_df': 5, 'vect__stop_words': None, ...           0.807198   \n",
       "4   {'vect__min_df': 3, 'vect__stop_words': ['i', ...           0.804627   \n",
       "10  {'vect__min_df': 5, 'vect__stop_words': ['i', ...           0.801628   \n",
       "11  {'vect__min_df': 5, 'vect__stop_words': ['i', ...           0.805056   \n",
       "5   {'vect__min_df': 3, 'vect__stop_words': ['i', ...           0.803770   \n",
       "14  {'vect__min_df': 10, 'vect__stop_words': None,...           0.805913   \n",
       "17  {'vect__min_df': 10, 'vect__stop_words': ['i',...           0.800343   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.812688           0.817402         0.812144        0.004532   \n",
       "12           0.808401           0.815688         0.812143        0.002978   \n",
       "6            0.811830           0.814831         0.811143        0.003327   \n",
       "13           0.805829           0.811402         0.807000        0.003224   \n",
       "1            0.807115           0.807115         0.807000        0.000163   \n",
       "2            0.807973           0.803686         0.806857        0.002275   \n",
       "16           0.800257           0.808401         0.806428        0.004457   \n",
       "3            0.807544           0.807115         0.806286        0.001486   \n",
       "7            0.808401           0.805401         0.806286        0.001502   \n",
       "15           0.804972           0.809687         0.805715        0.002987   \n",
       "9            0.807973           0.804544         0.804858        0.002425   \n",
       "8            0.803258           0.801972         0.804142        0.002223   \n",
       "4            0.798543           0.807973         0.803714        0.003904   \n",
       "10           0.802400           0.804972         0.803000        0.001430   \n",
       "11           0.801972           0.801972         0.803000        0.001454   \n",
       "5            0.799400           0.801543         0.801571        0.001784   \n",
       "14           0.800257           0.798114         0.801428        0.003290   \n",
       "17           0.798114           0.792542         0.797000        0.003281   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "12                2  \n",
       "6                 3  \n",
       "13                4  \n",
       "1                 5  \n",
       "2                 6  \n",
       "16                7  \n",
       "3                 8  \n",
       "7                 9  \n",
       "15               10  \n",
       "9                11  \n",
       "8                12  \n",
       "4                13  \n",
       "10               14  \n",
       "11               15  \n",
       "5                16  \n",
       "14               17  \n",
       "17               18  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram\n",
    "Un ulteriore strumento per ridurre la dimensionalità è quello di considerare non solo le singole parole ma anche tuple di parole. Questo è chiamato n-gram. Gli n-gram sono generalizzazioni di 2-gram, 3-gram, ecc. e sono fondamentalmente **sequenze di $n$ parole consecutive**. Nei casi più comuni sono al massimo composte da 2 o 3 parole. Ad esempio, per la frase \"I go to New York\" con $n = 2$ avremo\n",
    "- \"I go\"\n",
    "- \"go to\"\n",
    "- \"to New\"\n",
    "- \"New York\"\n",
    "\n",
    "di queste, chiaramente, solo \"New York\" è una n-gram valida, in quanto le altre non hanno significato proprio.\n",
    "La loro importanza sta nel fatto che potrei pensare di usarle come feature esattamente come uso le singole parole. Il fatto che li vada a generare tutti non è molto utile poiché solamente poche di esse hanno senso compiuto (nel mio esempio solo una su quattro)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
