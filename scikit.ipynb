{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8e3a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d489e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8c0d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([250000, 300000, 150000, 78000, 150000])\n",
    "X = np.array([[1, 3, 2000, 1, 0, 0], [1, 2, 800, 0, 1, 0], [1, 2, 850, 1, 0, 0], [1, 1, 550, 1, 0, 0], [1, 4, 2000, 0, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f400ddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.fit(X, y) #fit vuole come X una matrice, se abbiamo un array la otteniamo\n",
    "# a partire ad esempio da X[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "771aecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    2, 3300,    0,    1,    0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([1, 2, 3300, 0, 1, 0]).reshape(1, -1)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "695068a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([382352.94117655])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lrm.predict(X_new)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76918fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,  12.,  23.,  34.,  45.,  56.,  67.,  78.,  89., 100.]),\n",
       " array([[  4.],\n",
       "        [ 37.],\n",
       "        [ 70.],\n",
       "        [103.],\n",
       "        [136.],\n",
       "        [169.],\n",
       "        [202.],\n",
       "        [235.],\n",
       "        [268.],\n",
       "        [301.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.linspace(1, 100, 10)\n",
    "y = (3 * X + 1).reshape(-1, 1)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d25634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.fit(X[:, None], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73c703a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([200])\n",
    "y_pred = lrm.predict(X_new[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed90df77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[601.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c57b5d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.]]), array([1.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm.coef_, lrm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "babbf467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x147175af580>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00dcc1",
   "metadata": {},
   "source": [
    "#### Overfitting\n",
    "**overfitting** significa che il modello ha perso di generalità:\n",
    "risulta cioè troppo aderente ai dati di training e questo si ripercuote\n",
    "sul fatto che l'errore compiuto sui dati di training è notevolmente inferiore\n",
    "a quello compiuto sui dati di testing.\n",
    "Questo tipicamente accade perché, dal punto di vista matematico, i parametri\n",
    "ricalcano perfettamente la curva (se non lineare) che passa per i punti forniti\n",
    "in input in fase di training.\n",
    "\n",
    "Se volessimo verificare se c'è overfitting, potremmo ad esempio calcolare l'errore quadratico medio che c'è sulla predizione fatta sul dataset di training e su quello di validazione. Ad esempio cosi\n",
    "\n",
    "```python\n",
    "    lrm = LinearRegression()\n",
    "    lrm.fit(X_train, y_train)\n",
    "    np.mean((lrm.predict(X_train) - y_train)**2) \n",
    "    0.02291582249089107\n",
    "    np.mean((lrm.predict(X_val) - y_val)**2) \n",
    "    0.019989933582418993\n",
    "```\n",
    "Vediamo che rimaniamo sullo stesso ordine di grandezza e addirittura l'errore più grande è quello commesso sul set di training. Quindi non vi è overfitting.\n",
    "\n",
    "È anche possibile usare il **Mean Absolute Percentage Error** che non è altro che l'errore medio assoluto percentuale, che è molto più indicativo degli scarti quadratici medi.\n",
    "Si ottiene come\n",
    "\n",
    "$$\n",
    "\\text{MAPE} = \\frac{1}{m} \\sum_{i=1}^m | \\frac{\\tilde{y_i} - y_i}{y_i}|\n",
    "$$\n",
    "\n",
    "Banalmente potremo calcolarla come\n",
    "```python\n",
    "    np.mean(np.abs((lrm.predict(X_train) - y_train) / y_train))\n",
    "    0.05899891472169821\n",
    "    np.mean(np.abs((lrm.predict(X_val) - y_val) / y_val))\n",
    "    0.05170223216469662\n",
    "```\n",
    "\n",
    "Si può anche calcolare il cosiddetto **Coefficiente di determinazione $R^2$** che indica la proporzione fra variabilità dei dati e correttezza del modello.\n",
    "Si calcola come \n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\sum_{i=1}^m (\\tilde{y}_i - \\bar{y})^2}{\\sum_{i=1}^m (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "dove al numeratore si ha la sommatoria dei quadrati delle differenze di ogni $y_i$ predetta (per quello la tilde) e della $y$ media (con la barra), e al denominatore la sommatoria dei quadrati delle differenze fra la $y_i$ presa dai dati meno il valore medio della $y$\n",
    "\n",
    "Può variare nell'intervallo[0, 1], dove \n",
    "- 1 indica che il modello cattura perfettamente i dati\n",
    "- 0 non vi è alcuna relazione fra modello e dati\n",
    "\n",
    "Con **scikit-learn** si può calcolare con *lrm.score()* come segue\n",
    "\n",
    "```python \n",
    "    lrm.score(X_train, y_train)\n",
    "    0.768433269368844\n",
    "    lrm.score(X_val, y_val)\n",
    "    0.7508669565801295\n",
    "```\n",
    "\n",
    "#### Importanza dei dati\n",
    "I dati ovviamente servono per qualsiasi tipo di addestramento, tuttavia servono anche per la validazione del training. Cioè una parte dei dati in nostro possesso serviranno, una volta concluso il training, per verificare se è avvenuto correttamente. Come vengono suddivisi i dati in dati di training e di validation? Esistono diversi approcci.\n",
    "\n",
    "1. **Hold Out**. In altre parole si suddividono i dati in due insiemi (secondo una porzione definita come 70-30) in **training set** e **validation set**. Il primo servirà per il training, il secondo è usato dopo l'addestramento per controllare la *capacità di generalizzazione* del sistema, cioè capire se è in grado di predire una risposta su dati ignoti: se l'errore è simile a quello del training si assume che abbia generalizzato bene. Se invece è consistente significa che c'è *overfitting* o i dati di training raccolti non sono indicativi del dominio di appartenenza. Con scikit-learn possiamo suddividerli, ad esempio in 70-30, in automatico con il seguente codice \n",
    "\n",
    "```python \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.7)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7917c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
