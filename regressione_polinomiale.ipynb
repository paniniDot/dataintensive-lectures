{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2943a69",
   "metadata": {},
   "source": [
    "### Regressione polinomiale\n",
    "Esiste un certo tipo di regressione, se vogliamo più complicata rispetto alla lineare, chiamata **polinomiale**. Questo genere di regressione è detta tale poiché i parametri in input vengono inseriti in modelli di grado superiore al primo rispetto ad essi. Ad esempio se avessimo un modello $h(x)$ in un solo parametro (**monovariato**), questo potrebbe essere di questo tipo\n",
    "\n",
    "$$\n",
    "    h(x) = \\theta_0 + \\theta_1\\mathbf{x} + \\theta_2\\mathbf{x}^2 + \\cdots + \\theta_n\\mathbf{x}^n\n",
    "$$\n",
    "\n",
    "dove $\\mathbf{x}$ è in grassetto poiché da considerarsi come vettore.\n",
    "Se invece fosse **multivariata**, diciamo di due parametri $a, b$, essa risulterebbe di questa forma\n",
    "\n",
    "$$\n",
    "    h(a, b) = \\theta_0 + \\theta_1 \\cdot a + \\theta_2 \\cdot a^2 + \\theta_3 \\cdot b + \\theta_4 \\cdot a \\cdot b + \\theta_5 \\cdot b^2\n",
    "$$\n",
    "\n",
    "Va comunque sottolineato che questo genere di regressione è, si polinomiale rispetto ai parametri d'ingresso (che però sono noti a tempo d'esecuzione), ma rimane *lineare rispetto ai parametri $\\theta_i$* da determinare. \n",
    "\n",
    "#### Quando vengono usati questi modelli\n",
    "Se ricordiamo il problema della predizione di consumi sulla base delle temperature, ci ricordiamo che i dati erano modellabili linearmente (con una retta) in estate. Se però si visualizzavano i dati relativi allo storico anche invernale si verificava una situazione come questa \n",
    "<img src=\"imgs/consumi.PNG\" alt=\"Storico consumi\" width=\"300\">\n",
    "che chiaramente risulta non lineare, infatti se provassimo ad applicarvi la regressione lineare standard, il massimo che riusciremmo a ottenere è questo\n",
    "<img src=\"imgs/lineare_consumi.PNG\" alt=\"Andamento modello lineare\" width=\"300\">\n",
    "Il che risulta chiaramente inaccurato, cio viene confermato dai valori numerici quali\n",
    "- **errore quadratico medio** è 0.081\n",
    "- **errore relatrivo** è 14.4% (può sembrare anche accettabile)\n",
    "- **coefficiente $R^2$** è 0.028 (terribile)\n",
    "Perciò quello che intuitivamente e graficamente era ottenibile dai grafici, è stato dimostrato numericamente. In generale, pertanto, esistono fenomeni il cui andamento non è rappresentabile in un modello lineare (retta), per cui i modelli polinomiali sono più accurati.\n",
    "\n",
    "Tornando all'esempio di prima, se definissimo $\\mathbf{y}$ i consumi in funzione delle temperature $\\mathbf{x}$ potremmo provare a modellare il fenomeno con una funzione quadratica\n",
    "\n",
    "$$\n",
    "\\tilde{\\mathbf{y}} = \\theta_0 + \\theta_1 \\cdot \\mathbf{x} + \\theta_2 \\cdot \\mathbf{x}^2\n",
    "$$\n",
    "\n",
    "di cui, come per la regessione lineare, andrà minimizzato l'errore quadratico medio $E(\\theta)$ \n",
    "\n",
    "$$\n",
    "E(\\theta) = \\frac{1}{m} \\sum_{i=1}^m (\\theta_0 + \\theta_1 \\cdot {x}_i + \\theta_2 \\cdot {x}_i^2 - {y}_i)^2\n",
    "$$\n",
    "(questa volta $x_i, y_i$ non in grassetto poiché sono i singoli termini dei due vettori).\n",
    "\n",
    "Per fare ciò occorrerà calcolare le derivate parziali rispetto a ciascun $\\theta_j$ impiegato (con $j \\in [0, 2]$)\n",
    "Cioè in altre parole si calcolano, in questo caso\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial E(\\theta)}{\\theta_0} = \\frac{2}{m} \\sum_{i=1}^m (\\theta_0 + \\theta_1 \\cdot {x}_i + \\theta_2 \\cdot {x}_i^2 - {y}_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E(\\theta)}{\\theta_1} = \\frac{2}{m} \\sum_{i=1}^m (\\theta_0 + \\theta_1 \\cdot {x}_i + \\theta_2 \\cdot {x}_i^2 - {y}_i)\\cdot {x}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial E(\\theta)}{\\theta_2} = \\frac{2}{m} \\sum_{i=1}^m (\\theta_0 + \\theta_1 \\cdot {x}_i + \\theta_2 \\cdot {x}_i^2 - {y}_i)^2 \\cdot {x}^2_i\n",
    "$$\n",
    "\n",
    "A questo punto andando a sostituire i vari valori di $x_i, y_i$ otterremo delle funzioni lineari multivariate rispetto ai $\\theta_i$ che costituiranno il passo di miglioramento. Infatti come per la regressione lineare dove la discesa sul gradiente era calcolata come\n",
    "\n",
    "$$\n",
    "    \\mathbf{x}_{k+1} = \\mathbf{x}_k - \\eta \\cdot \\nabla f(\\mathbf{x}_k)\n",
    "$$\n",
    "\n",
    "con $\\eta$ tasso di *learning rate* anche qui è la stessa cosa infatti sostituendo dei valori reali (vedi le slide del prof per vedere quali), otterremo che la discesa del gradiente si esegue come segue\n",
    "\n",
    "$$\n",
    "\\theta_0^{k+1} = \\theta_0^k - \\eta(-4.37 + 2\\theta_0^k + 52.8\\theta_1^k + 1395.37\\theta_2^k)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_1^{k+1} = \\theta_1^k - \\eta(-115.52 + 52.8\\theta_0^k + 1395.37\\theta_1^k + 36913.6\\theta_2^k)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\theta_2^{k+1} = \\theta_2^k - \\eta(-3054.72 + 1395.37\\theta_0^k + 36913.6\\theta_1^k + 977487\\theta_2^k)\n",
    "$$\n",
    "\n",
    "Con questi dati, minimizzare l'errore (o discendere il gradiente) rispetto a un polinomio di secondo grado, significa trovare i coefficienti $\\theta_0, \\theta_1, \\theta_2$ tali per cui l'equazione della parabola risulti la seguente\n",
    "<img src=\"imgs/quadratica_consumi.PNG\" alt=\"Andamento modello quadratico\" width=\"300\">\n",
    "La cosa interessante da sottolineare è che con questo modello avremo i seguenti valori numerici\n",
    "- **errore quadratico medio** è 0.036\n",
    "- **errore relatrivo** è 8.8% \n",
    "- **coefficiente $R^2$** è 0.566 \n",
    "Se decidessimo di spingerci oltre utilizzando un modello di terzo grado\n",
    "\n",
    "$$\n",
    "    \\tilde{\\mathbf{y}} = \\theta_0 + \\theta_1 \\cdot \\mathbf{x} + \\theta_2 \\cdot \\mathbf{x}^2 + \\theta_3 \\cdot \\mathbf{x}^3\n",
    "$$\n",
    "\n",
    "Vedremmo che il modello si comporta ancora meglio, cioè graficamente insegue meglio i dati\n",
    "<img src=\"imgs/cubica_consumi.PNG\" alt=\"Andamento modello cubico\" width=\"300\">\n",
    "e numericamente risulta: \n",
    "- **errore quadratico medio** è 0.025\n",
    "- **errore relatrivo** è 6.9% \n",
    "- **coefficiente $R^2$** è 0.703 \n",
    "Si può migliorare ancora fino ad arrivare, ad esempio, a un polinomio di grado 10.\n",
    "#### Come creare modelli di questo tipo con scikit-learn\n",
    "È importante sottolineare che ogni buona implementazione di algoritmi di ML, deve offrire la possibilità di *aumentare a piacere* la complessità del modello, anche non modificando i dati in input. In altre parole in ogni momento io potrei voler aumentare il numero di parametri, e questo dev'essere *sempre* possibile. Scikit-learn offre questa possibilità, infatti esistono diverse classi per pre-elaborare i dati, e aggiungere ulteriori feature, offrendo comunque una API comune.\n",
    "##### Polynomial Features\n",
    "In particolare esiste la classe **PolynomialFeatures** che aggiunge alle variabili di grado 1 che vengono fornite in input tutte quelle del grado $N$ che gli passiamo come *iperparametro*.\n",
    "Ad esempio con il seguente codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05eecd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,  10.,   4.,  20., 100.],\n",
       "       [  1.,  -3.,  20.,   9., -60., 400.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train = np.array([[2, 10], [-3, 20]])\n",
    "poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a4a2ad",
   "metadata": {},
   "source": [
    "che non è altro che lo sviluppo fino al secondo grado della $\\mathbf{X}$. Infatti se considerassi un'espressione polinomiale di grado secondo a due elementi $a,b$, il modello diventerebbe\n",
    "\n",
    "$$\n",
    "    h(a,b) = \\theta_0 + \\theta_1 \\cdot a + \\theta_2 \\cdot b + \\theta_3\\cdot a^2 + \\theta_4 \\cdot a \\cdot b + \\theta_5 \\cdot b^2   \n",
    "$$\n",
    "\n",
    "da cui notiamo che i parametri da ricavare passano da essere tre ($\\theta_0, \\theta_1, \\theta_2$) a essere 5 con conseguenza avere un modello più accurato.\n",
    "\n",
    "In altre parole si è passato da un array di questo tipo\n",
    "\n",
    "| **_a_** | **_b_** |\n",
    "|:-------:|:-------:|\n",
    "|    2    |    10   |\n",
    "|    -3   |    20   |\n",
    "\n",
    "a uno di questo tipo\n",
    "\n",
    "| **_1_** | **_a_** | **_b_** | **_a^2_** | **_a b_** | **b^2** |\n",
    "|:-------:|:-------:|:-------:|:---------:|:---------:|:-------:|\n",
    "|    1    |    2    |    10   |     4     |     20    |   100   |\n",
    "|    1    |    -3   |    20   |     9     |    -60    |   400   |\n",
    "\n",
    "a questo punto, rimanendo, come già detto, il modello lineare, cioè i parametri $\\theta_i$ da trovare rimangono solo al primo grado, potrò tranquillamente utilizzare un modello di regressione lineare fornito da *scikit-learn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "129316d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "prm = LinearRegression()\n",
    "y_train = np.array([5, 35])\n",
    "prm.fit(poly.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c55545",
   "metadata": {},
   "source": [
    "A questo punto il sistema è trainato, occorrerà testarlo con *prm.predict()*. Per fare ciò, poiché il modello è addestrato per lavorare con 6 parametri e non più 3, occorrerà trasformare anche qualsiasi altro valore si introduca. Per farlo si usa `poly.transform()` e non `poly.fit_transform()` poiché è già stato costruito il modello, ora occorre solo usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62d8ca5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.15639565])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = np.array([2, 3])\n",
    "prm.predict(poly.transform(X_val[None, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd3a93",
   "metadata": {},
   "source": [
    "Con `X_val[None, :]` si ottiene un array di array, cioè `[[2,3]]`, questo serve poiché `poly.transform()` acetta come parametro solamente un array di array come lo era `X_train`.\n",
    "\n",
    "###### Pipeline\n",
    "Lavorare facendo prima trasformazione e poi training risulta scomodo. Ecco perché *scikit-learn* offre un oggetto ***Pipeline*** che incapsula queste due classi astraendo le due cose. In altre parole non sembrerà di star lavorando con dei modelli che hanno subito una trasformazione al grado $N$.\n",
    "<img src=\"imgs/pipeline.PNG\" alt=\"Pipeline\" width=\"500\">\n",
    "In particolare si esegue in questo modo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cd4975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "prm = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b08808",
   "metadata": {},
   "source": [
    "Dove le stringhe da affiancare servono a noi per riconoscere le due parti di cui è composta la pipeline.\n",
    "A questo punto non ci preoccupiamo più di trasformare i dati in input al training, o quelli per cui vogliamo predire la $y$, usiamo la pipeline come se fosse una comune ***LinearRegression***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86b0dc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly', PolynomialFeatures(include_bias=False)),\n",
       "                ('linreg', LinearRegression())])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a1bce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.15639565])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prm.predict(X_val[None, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f7b80aa",
   "metadata": {},
   "source": [
    "## Overfitting vs Generalizzazione\n",
    "Sono due concetti posti agli antipodi. Infatti, guardando la seguente figura\n",
    "<img src=\"imgs/overfitting.PNG\" alt=\"overfitting\" width=\"270\">\n",
    "notiamo che all'aumentare della complessità del modello l'errore commesso sul training set (linea in blu), tenderà a zero. Questo perché banalmente maggiore è la complessità e più il modello si adatterà ai dati forniti in training. Tuttavia sul validation set(la linea rossa), man mano che aumenta scenderà fino a toccare un punto di minimo dopo il quale, all'aumentare ulteriormente del modello, l'errore ricomincerà a salire, questo perché il modello perderà di generalità.\n",
    "Esiste poi una classificazione dei vari modelli in\n",
    "- **Underfitting**. Il modello scelto in questo caso è troppo semplice e dunque inadeguato per rappresentare il dominio. Risulta impreciso sia in fase di training che di validation.\n",
    "- **Optimal**. In questo caso il modello è della giusta complessità, cioè generalizza perfettamente il fenomeno. Si comporterà adeguatamente sia in fase di training che di validation.\n",
    "- ***Overfitting***. Il modello ricalca troppo fedelmente i dati forniti in fase di training e dunque perderà di generalità. L'errore commesso sul validation set risulta notevolmente maggiore rispetto a quello sul training.\n",
    "Sono riassunti graficamente i tre tipi di modello\n",
    "<img src=\"imgs/modelli.PNG\" alt=\"modelli a confronto\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30518eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
